#!/usr/bin/env node

import { execSync } from 'child_process';
import { readFileSync, writeFileSync, existsSync } from 'fs';
import { join } from 'path';

/**
 * Production Setup Script
 *
 * This script helps set up the production environment by:
 * 1. Creating production-ready environment configuration
 * 2. Setting up PostgreSQL database configuration
 * 3. Running database migrations
 * 4. Setting up security configurations
 */

const __dirname = new URL('.', import.meta.url).pathname;
const rootDir = join(__dirname, '..');

// Colors for console output
const colors = {
  green: '\x1b[32m',
  yellow: '\x1b[33m',
  red: '\x1b[31m',
  blue: '\x1b[34m',
  reset: '\x1b[0m',
  bold: '\x1b[1m'
};

const log = (message, color = 'reset') => {
  console.log(`${colors[color]}${message}${colors.reset}`);
};

const logStep = (step, message) => {
  log(`\n${colors.bold}[${step}]${colors.reset} ${colors.blue}${message}${colors.reset}`);
};

const logSuccess = (message) => {
  log(`‚úÖ ${message}`, 'green');
};

const logWarning = (message) => {
  log(`‚ö†Ô∏è  ${message}`, 'yellow');
};

const logError = (message) => {
  log(`‚ùå ${message}`, 'red');
};

// Production environment template
const productionEnvTemplate = `# Production Environment Configuration
# Generated by setup-production.js

# Application Environment
NODE_ENV=production
PORT=3001

# Database Configuration (PostgreSQL)
DATABASE_URL="postgresql://username:password@localhost:5432/sesimiz_ol_prod?schema=public"

# JWT Configuration
JWT_SECRET="your-super-secure-jwt-secret-here-change-this"
JWT_EXPIRES_IN="24h"
JWT_REFRESH_EXPIRES_IN="7d"

# CORS Configuration
CORS_ALLOWED_ORIGINS="https://your-domain.com,https://www.your-domain.com"
CORS_CREDENTIALS=true

# Security Configuration
SECURITY_HEADERS_ENABLED=true
SECURITY_HEADERS_REPORT_ONLY=false
TRUST_PROXY=1

# Firebase Configuration (for Email)
FIREBASE_PROJECT_ID="your-firebase-project-id"
FIREBASE_CLIENT_EMAIL="your-firebase-client-email"
FIREBASE_PRIVATE_KEY="your-firebase-private-key"

# Email Configuration
EMAIL_FROM="noreply@your-domain.com"
FRONTEND_URL="https://your-domain.com"

# Feature Flags
FEATURE_REALTIME_NOTIFICATIONS=true
FEATURE_ADMIN_PANEL=true
FEATURE_STORY_MODERATION=true
FEATURE_USER_MESSAGING=true

# Rate Limiting
RATE_LIMIT_ENABLED=true
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100

# File Upload Limits
UPLOAD_MAX_FILE_SIZE=5242880
UPLOAD_ALLOWED_TYPES="image/jpeg,image/png,image/webp"

# Admin Configuration
ADMIN_PANEL_SECRET="your-admin-panel-secret"

# Content Security Policy
SECURITY_CSP_SCRIPT_SRC="'self'"
SECURITY_CSP_STYLE_SRC="'self','unsafe-inline',https://fonts.googleapis.com"
SECURITY_CSP_FONT_SRC="'self',https://fonts.gstatic.com"
SECURITY_CSP_IMG_SRC="'self',data:,blob:,https:"
SECURITY_CSP_CONNECT_SRC="'self',https:"

# Monitoring and Logging
LOG_LEVEL=info
LOG_FORMAT=json

# Session Configuration
SESSION_SECRET="your-session-secret-here"
SESSION_SECURE=true
SESSION_HTTP_ONLY=true
SESSION_SAME_SITE=strict
`;

// PostgreSQL schema setup SQL
const postgresqlSetupSQL = `
-- PostgreSQL Production Database Setup
-- Run this after creating your PostgreSQL database

-- Enable required extensions
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

-- Create indexes for better performance
-- Note: Prisma will create basic indexes, these are additional optimizations

-- User performance indexes
CREATE INDEX IF NOT EXISTS idx_users_email_verified ON users(email_verified);
CREATE INDEX IF NOT EXISTS idx_users_role_active ON users(role, is_active);
CREATE INDEX IF NOT EXISTS idx_users_created_at ON users(created_at);

-- Story performance indexes
CREATE INDEX IF NOT EXISTS idx_stories_status_created ON stories(status, created_at);
CREATE INDEX IF NOT EXISTS idx_stories_author_status ON stories(author_id, status);
CREATE INDEX IF NOT EXISTS idx_stories_view_count ON stories(view_count DESC);

-- Notification performance indexes
CREATE INDEX IF NOT EXISTS idx_notifications_user_read_created ON notifications(user_id, read, created_at);
CREATE INDEX IF NOT EXISTS idx_notifications_type_created ON notifications(type, created_at);

-- Comment performance indexes
CREATE INDEX IF NOT EXISTS idx_comments_story_created ON comments(story_id, created_at);
CREATE INDEX IF NOT EXISTS idx_comments_author_created ON comments(author_id, created_at);

-- Message performance indexes
CREATE INDEX IF NOT EXISTS idx_messages_sender_created ON messages(sender_id, created_at);
CREATE INDEX IF NOT EXISTS idx_messages_receiver_created ON messages(receiver_id, created_at);
CREATE INDEX IF NOT EXISTS idx_messages_read_at ON messages(read_at);

-- Session management indexes
CREATE INDEX IF NOT EXISTS idx_user_sessions_expires ON user_sessions(expires_at);
CREATE INDEX IF NOT EXISTS idx_user_sessions_user_active ON user_sessions(user_id, revoked_at);

-- Security indexes
CREATE INDEX IF NOT EXISTS idx_password_reset_tokens_expires ON password_reset_tokens(expires_at);
CREATE INDEX IF NOT EXISTS idx_password_reset_tokens_hash ON password_reset_tokens(token_hash);

-- Organization indexes
CREATE INDEX IF NOT EXISTS idx_organizations_status_type ON organizations(status, type);
CREATE INDEX IF NOT EXISTS idx_organization_members_org_user ON organization_members(organization_id, user_id);

-- Full-text search setup (optional - uncomment if needed)
-- ALTER TABLE stories ADD COLUMN search_vector tsvector;
-- CREATE INDEX idx_stories_search ON stories USING gin(search_vector);
-- CREATE OR REPLACE FUNCTION update_story_search_vector() RETURNS trigger AS $$
-- BEGIN
--   NEW.search_vector := to_tsvector('turkish', COALESCE(NEW.title, '') || ' ' || COALESCE(NEW.content, ''));
--   RETURN NEW;
-- END;
-- $$ LANGUAGE plpgsql;
-- CREATE TRIGGER trig_update_story_search BEFORE INSERT OR UPDATE ON stories
--   FOR EACH ROW EXECUTE FUNCTION update_story_search_vector();
`;

function createProductionEnv() {
  logStep('1', 'Creating production environment configuration');

  const envPath = join(rootDir, '.env.production');

  if (existsSync(envPath)) {
    logWarning('Production .env file already exists. Backing up...');
    const backupPath = join(rootDir, `.env.production.backup.${Date.now()}`);
    const existingContent = readFileSync(envPath, 'utf8');
    writeFileSync(backupPath, existingContent);
    logSuccess(`Backed up existing .env.production to ${backupPath}`);
  }

  writeFileSync(envPath, productionEnvTemplate);
  logSuccess('Created .env.production template');

  log('\nüìù Please edit .env.production and update the following:');
  log('   - DATABASE_URL with your PostgreSQL connection string');
  log('   - JWT_SECRET with a secure random string');
  log('   - Firebase configuration for email services');
  log('   - CORS_ALLOWED_ORIGINS with your domain(s)');
  log('   - All other secrets and configuration values');
}

function createPostgreSQLSetup() {
  logStep('2', 'Creating PostgreSQL setup script');

  const sqlPath = join(rootDir, 'scripts', 'setup-postgresql.sql');
  writeFileSync(sqlPath, postgresqlSetupSQL);
  logSuccess('Created PostgreSQL setup script');

  log('\nüìù To set up PostgreSQL:');
  log('   1. Create a new PostgreSQL database');
  log('   2. Run: psql -d your_database -f scripts/setup-postgresql.sql');
  log('   3. Update DATABASE_URL in .env.production');
}

function updatePrismaSchema() {
  logStep('3', 'Updating Prisma schema for production');

  const schemaPath = join(rootDir, 'prisma', 'schema.prisma');
  let schemaContent = readFileSync(schemaPath, 'utf8');

  // Create production schema backup
  const backupPath = join(rootDir, 'prisma', 'schema.prisma.backup');
  writeFileSync(backupPath, schemaContent);

  // Update datasource for production
  const productionDatasource = `
datasource db {
  provider = "postgresql"
  url      = env("DATABASE_URL")
}`;

  // Replace SQLite datasource with PostgreSQL
  schemaContent = schemaContent.replace(
    /datasource db \{[\s\S]*?\}/,
    productionDatasource.trim()
  );

  writeFileSync(schemaPath, schemaContent);
  logSuccess('Updated Prisma schema for PostgreSQL');

  log('\nüìù Schema changes:');
  log('   - Switched from SQLite to PostgreSQL');
  log('   - Backup saved to prisma/schema.prisma.backup');
}

function createDeploymentScript() {
  logStep('4', 'Creating deployment script');

  const deployScript = `#!/bin/bash

# Production Deployment Script for Sesimiz Ol
# This script handles the complete production deployment process

set -e  # Exit on any error

echo "üöÄ Starting production deployment..."

# Load environment variables
if [ -f .env.production ]; then
    export $(cat .env.production | grep -v '^#' | xargs)
    echo "‚úÖ Loaded production environment variables"
else
    echo "‚ùå .env.production file not found!"
    exit 1
fi

# Install dependencies
echo "üì¶ Installing dependencies..."
npm ci --only=production

# Generate Prisma client
echo "üóÑÔ∏è  Generating Prisma client..."
npm run prisma:generate

# Run database migrations
echo "üóÑÔ∏è  Running database migrations..."
npm run prisma:deploy

# Build the application (if needed)
echo "üî® Building application..."
npm run build

# Run production tests (optional)
if [ "$RUN_TESTS" = "true" ]; then
    echo "üß™ Running production tests..."
    npm test
fi

# Start the application
echo "üöÄ Starting application in production mode..."
exec npm run start:production
`;

  const deployPath = join(rootDir, 'scripts', 'deploy-production.sh');
  writeFileSync(deployPath, deployScript);

  // Make script executable
  try {
    execSync(`chmod +x ${deployPath}`);
  } catch (error) {
    logWarning('Could not make deploy script executable (Windows?)');
  }

  logSuccess('Created deployment script');
}

function createDockerConfig() {
  logStep('5', 'Creating Docker configuration');

  const dockerfile = `# Production Dockerfile for Sesimiz Ol Backend
FROM node:18-alpine

# Install dependencies for sharp (image processing)
RUN apk add --no-cache libc6-compat

# Set working directory
WORKDIR /app

# Copy package files
COPY package*.json ./
COPY prisma ./prisma/

# Install dependencies
RUN npm ci --only=production && npm cache clean --force

# Generate Prisma client
RUN npx prisma generate

# Copy application code
COPY . .

# Create non-root user
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nodejs -u 1001

# Set ownership and permissions
RUN chown -R nodejs:nodejs /app
USER nodejs

# Expose port
EXPOSE 3001

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\
  CMD node -e "require('http').get('http://localhost:3001/health', (res) => { process.exit(res.statusCode === 200 ? 0 : 1) })"

# Start the application
CMD ["npm", "run", "start:production"]
`;

  const dockerCompose = `version: '3.8'

services:
  backend:
    build: .
    ports:
      - "3001:3001"
    environment:
      - NODE_ENV=production
    env_file:
      - .env.production
    depends_on:
      - postgres
    restart: unless-stopped
    volumes:
      - ./uploads:/app/uploads

  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: sesimiz_ol_prod
      POSTGRES_USER: sesimiz_ol
      POSTGRES_PASSWORD: \${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/setup-postgresql.sql:/docker-entrypoint-initdb.d/setup.sql
    ports:
      - "5432:5432"
    restart: unless-stopped

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
    depends_on:
      - backend
    restart: unless-stopped

volumes:
  postgres_data:
`;

  writeFileSync(join(rootDir, 'Dockerfile.production'), dockerfile);
  writeFileSync(join(rootDir, 'docker-compose.production.yml'), dockerCompose);

  logSuccess('Created Docker configuration files');
}

function createNginxConfig() {
  logStep('6', 'Creating Nginx configuration');

  const nginxConfig = `events {
    worker_connections 1024;
}

http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    # Security headers
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";
    add_header Referrer-Policy "strict-origin-when-cross-origin";

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=upload:10m rate=1r/s;

    upstream backend {
        server backend:3001;
    }

    server {
        listen 80;
        server_name your-domain.com www.your-domain.com;
        return 301 https://$server_name$request_uri;
    }

    server {
        listen 443 ssl http2;
        server_name your-domain.com www.your-domain.com;

        # SSL configuration
        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384;
        ssl_prefer_server_ciphers off;

        # API routes
        location /api/ {
            limit_req zone=api burst=20 nodelay;
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
        }

        # WebSocket support for real-time notifications
        location /socket.io/ {
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # File uploads
        location /api/upload/ {
            limit_req zone=upload burst=5 nodelay;
            client_max_body_size 10M;
            proxy_pass http://backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # Static files
        location /uploads/ {
            proxy_pass http://backend;
            expires 1y;
            add_header Cache-Control "public, immutable";
        }

        # Health check
        location /health {
            proxy_pass http://backend;
            access_log off;
        }

        # Frontend (if serving from same domain)
        location / {
            try_files $uri $uri/ /index.html;
            expires 1h;
            add_header Cache-Control "public";
        }
    }
}
`;

  const nginxDir = join(rootDir, 'nginx');
  try {
    execSync(`mkdir -p ${nginxDir}`);
  } catch (error) {
    // Directory might already exist
  }

  writeFileSync(join(nginxDir, 'nginx.conf'), nginxConfig);
  logSuccess('Created Nginx configuration');
}

async function generateSecrets() {
  logStep('7', 'Generating secure secrets');

  const crypto = await import('crypto');

  const secrets = {
    JWT_SECRET: crypto.randomBytes(64).toString('hex'),
    SESSION_SECRET: crypto.randomBytes(32).toString('hex'),
    ADMIN_PANEL_SECRET: crypto.randomBytes(16).toString('hex')
  };

  const secretsFile = join(rootDir, 'secrets.txt');
  const secretsContent = Object.entries(secrets)
    .map(([key, value]) => `${key}=${value}`)
    .join('\n');

  writeFileSync(secretsFile, secretsContent);
  logSuccess('Generated secure secrets in secrets.txt');

  log('\nüîê Copy these secrets to your .env.production file:');
  Object.entries(secrets).forEach(([key, value]) => {
    log(`   ${key}=${value}`);
  });

  logWarning('Delete secrets.txt after copying the values!');
}

async function main() {
  try {
    log(`${colors.bold}${colors.blue}üöÄ Sesimiz Ol Production Setup${colors.reset}\n`);
    log('This script will set up your production environment.\n');

    createProductionEnv();
    createPostgreSQLSetup();
    updatePrismaSchema();
    createDeploymentScript();
    createDockerConfig();
    createNginxConfig();
    await generateSecrets();

    log(`\n${colors.bold}${colors.green}‚úÖ Production setup completed!${colors.reset}\n`);

    log('üìã Next steps:');
    log('1. Edit .env.production with your actual values');
    log('2. Set up PostgreSQL database');
    log('3. Run: npm run prisma:deploy');
    log('4. Configure your domain and SSL certificates');
    log('5. Deploy using Docker Compose or your preferred method');

    log(`\n${colors.yellow}‚ö†Ô∏è  Important security notes:${colors.reset}`);
    log('- Change all default secrets and passwords');
    log('- Set up proper SSL certificates');
    log('- Configure firewall rules');
    log('- Enable monitoring and logging');
    log('- Regular security updates');

  } catch (error) {
    logError(`Setup failed: ${error.message}`);
    process.exit(1);
  }
}

main();